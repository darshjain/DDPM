"""
plot_evaluation.py
==================

Visualization tool for diffusion model evaluation results.

Purpose:
--------
Reads pre-computed evaluation metrics from JSON and creates publication-quality
plots without re-running expensive evaluations. Useful for regenerating plots
with different styles or after adding more checkpoint evaluations.

What it does:
-------------
- Loads evaluation results from 'evaluation_results.json'
- Creates two side-by-side plots:
  * FID (Fr√©chet Inception Distance) vs training steps
  * Inception Score with error bars vs training steps
- Highlights best performing checkpoints with star markers
- Prints summary table of all results to console
- Saves high-resolution plot image

Usage:
------
  python plot_evaluation.py

Requirements:
-------------
- evaluation_results.json must exist (generated by evaluate_checkpoints.py)

Output:
-------
- evaluation_curves.png: High-resolution visualization (300 DPI)
- Console output with summary table and best checkpoint information

Workflow:
---------
1. Run evaluate_checkpoints.py first (slow, computes all metrics)
2. Run this script to visualize results (fast, just plotting)
3. Re-run this script anytime to regenerate plots with tweaks

Note: This is much faster than evaluate_checkpoints.py since it only reads
      cached results and creates plots, without generating images or computing metrics.
"""

import json
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path

def main():
    # Load results
    results_file = 'evaluation_results.json'
    
    if not Path(results_file).exists():
        print(f"Error: {results_file} not found!")
        print("Please run evaluate_checkpoints.py first to generate the results.")
        return
    
    with open(results_file, 'r') as f:
        evaluation_results = json.load(f)
    
    # Extract data
    epochs = sorted([int(e) for e in evaluation_results.keys()])
    fid_scores = [evaluation_results[str(e)]['fid_score'] for e in epochs]
    is_means = [evaluation_results[str(e)]['is_mean'] for e in epochs]
    is_stds = [evaluation_results[str(e)]['is_std'] for e in epochs]
    
    # Filter out None values
    valid_fid = [(e, f) for e, f in zip(epochs, fid_scores) if f is not None]
    valid_is = [(e, m, s) for e, m, s in zip(epochs, is_means, is_stds) if m is not None and s is not None]
    
    if not valid_fid and not valid_is:
        print("No valid evaluation results found!")
        return
    
    # Create plots
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    
    # FID plot
    if valid_fid:
        fid_epochs, fid_vals = zip(*valid_fid)
        ax1.plot(fid_epochs, fid_vals, marker='o', linewidth=2, markersize=8, color='#2E86AB')
        ax1.set_xlabel('Training Steps', fontsize=12)
        ax1.set_ylabel('FID Score (lower is better)', fontsize=12)
        ax1.set_title('Fr√©chet Inception Distance vs Training Steps', fontsize=14, fontweight='bold')
        ax1.grid(True, alpha=0.3)
        
        # Find best FID
        best_fid_idx = np.argmin(fid_vals)
        best_fid_epoch = fid_epochs[best_fid_idx]
        best_fid_score = fid_vals[best_fid_idx]
        ax1.plot(best_fid_epoch, best_fid_score, 'r*', markersize=20, 
                label=f'Best: {best_fid_score:.4f} at step {best_fid_epoch}')
        ax1.legend(fontsize=10)
        print(f"\nüèÜ Best FID Score: {best_fid_score:.4f} at step {best_fid_epoch}")
    else:
        ax1.text(0.5, 0.5, 'No FID data available', 
                ha='center', va='center', transform=ax1.transAxes)
    
    # IS plot
    if valid_is:
        is_epochs, is_vals, is_err = zip(*valid_is)
        ax2.errorbar(is_epochs, is_vals, yerr=is_err, marker='o', linewidth=2, 
                    markersize=8, capsize=5, color='#A23B72')
        ax2.set_xlabel('Training Steps', fontsize=12)
        ax2.set_ylabel('Inception Score (higher is better)', fontsize=12)
        ax2.set_title('Inception Score vs Training Steps', fontsize=14, fontweight='bold')
        ax2.grid(True, alpha=0.3)
        
        # Find best IS
        best_is_idx = np.argmax(is_vals)
        best_is_epoch = is_epochs[best_is_idx]
        best_is_score = is_vals[best_is_idx]
        best_is_std = is_err[best_is_idx]
        ax2.plot(best_is_epoch, best_is_score, 'r*', markersize=20,
                label=f'Best: {best_is_score:.4f}¬±{best_is_std:.4f} at step {best_is_epoch}')
        ax2.legend(fontsize=10)
        print(f"üèÜ Best IS Score: {best_is_score:.4f}¬±{best_is_std:.4f} at step {best_is_epoch}")
    else:
        ax2.text(0.5, 0.5, 'No IS data available', 
                ha='center', va='center', transform=ax2.transAxes)
    
    plt.tight_layout()
    output_file = 'evaluation_curves.png'
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"\n‚úì Plots saved to {output_file}")
    
    # Print summary table
    print("\n" + "="*70)
    print("EVALUATION SUMMARY")
    print("="*70)
    print(f"{'Step':<10} {'FID Score':<15} {'Inception Score':<25}")
    print("-"*70)
    
    for epoch in epochs:
        fid = evaluation_results[str(epoch)]['fid_score']
        is_mean = evaluation_results[str(epoch)]['is_mean']
        is_std = evaluation_results[str(epoch)]['is_std']
        
        fid_str = f"{fid:.4f}" if fid is not None else "N/A"
        is_str = f"{is_mean:.4f}¬±{is_std:.4f}" if is_mean is not None and is_std is not None else "N/A"
        
        print(f"{epoch:<10} {fid_str:<15} {is_str:<25}")
    print("="*70)


if __name__ == '__main__':
    main()
